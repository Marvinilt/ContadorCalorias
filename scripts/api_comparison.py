#!/usr/bin/env python3
"""
Script para comparar precisiÃ³n y rendimiento de las APIs
Fase 1 - DÃ­as 3-4: EvaluaciÃ³n comparativa
"""

import json
import time
from pathlib import Path
from typing import Dict, List
from test_apis import APITester
import os
from dotenv import load_dotenv

class APIComparison:
    def __init__(self):
        load_dotenv()
        self.tester = APITester()
        self.results = {
            "comparison_date": time.strftime("%Y-%m-%d %H:%M:%S"),
            "test_images": [],
            "api_performance": {},
            "recommendations": {}
        }
    
    def run_comparison(self, test_images: List[str]):
        """Ejecutar comparaciÃ³n completa entre APIs"""
        print("ðŸ”¬ COMPARACIÃ“N DE APIs DE VISIÃ“N")
        print("=" * 50)
        
        config = {
            "openai_api_key": os.getenv("OPENAI_API_KEY"),
            "usda_api_key": os.getenv("USDA_API_KEY"),
            "nutritionix_app_id": os.getenv("NUTRITIONIX_APP_ID"),
            "nutritionix_app_key": os.getenv("NUTRITIONIX_APP_KEY")
        }
        
        for image_path in test_images:
            if not Path(image_path).exists():
                print(f"âš ï¸  Imagen no encontrada: {image_path}")
                continue
            
            print(f"\nðŸ“¸ Analizando: {Path(image_path).name}")
            print("-" * 30)
            
            image_results = {
                "image_path": image_path,
                "apis_tested": {},
                "processing_times": {},
                "costs": {}
            }
            
            # Test OpenAI Vision
            if config["openai_api_key"]:
                start_time = time.time()
                result = self.tester.test_openai_vision(image_path, config["openai_api_key"])
                processing_time = time.time() - start_time
                
                image_results["apis_tested"]["openai"] = result
                image_results["processing_times"]["openai"] = processing_time
                image_results["costs"]["openai"] = result.get("cost_estimate", 0)
                
                print(f"ðŸ¤– OpenAI Vision: {processing_time:.2f}s - ${result.get('cost_estimate', 0):.4f}")
            
            self.results["test_images"].append(image_results)
        
        # Generar anÃ¡lisis comparativo
        self._analyze_performance()
        self._generate_recommendations()
        self._save_comparison_results()
    
    def _analyze_performance(self):
        """Analizar rendimiento de las APIs"""
        if not self.results["test_images"]:
            return
        
        # Calcular mÃ©tricas promedio
        openai_times = []
        openai_costs = []
        
        for image_result in self.results["test_images"]:
            if "openai" in image_result["processing_times"]:
                openai_times.append(image_result["processing_times"]["openai"])
                openai_costs.append(image_result["costs"]["openai"])
        
        if openai_times:
            self.results["api_performance"]["openai"] = {
                "avg_processing_time": sum(openai_times) / len(openai_times),
                "avg_cost_per_image": sum(openai_costs) / len(openai_costs),
                "total_images_processed": len(openai_times),
                "success_rate": len([r for r in self.results["test_images"] 
                                   if r["apis_tested"].get("openai", {}).get("status") == "success"]) / len(openai_times)
            }
    
    def _generate_recommendations(self):
        """Generar recomendaciones basadas en los resultados"""
        recommendations = []
        
        # AnÃ¡lisis de OpenAI Vision
        openai_perf = self.results["api_performance"].get("openai", {})
        if openai_perf:
            avg_time = openai_perf.get("avg_processing_time", 0)
            avg_cost = openai_perf.get("avg_cost_per_image", 0)
            success_rate = openai_perf.get("success_rate", 0)
            
            if success_rate > 0.8:
                recommendations.append("âœ… OpenAI Vision muestra alta precisiÃ³n para reconocimiento de alimentos")
            
            if avg_time < 5:
                recommendations.append("âœ… Tiempo de respuesta de OpenAI Vision es aceptable para MVP")
            else:
                recommendations.append("âš ï¸ Tiempo de respuesta de OpenAI Vision podrÃ­a ser optimizado")
            
            # EstimaciÃ³n de costos mensuales
            monthly_cost_1k_users = avg_cost * 5 * 30 * 1000  # 5 fotos/dÃ­a, 30 dÃ­as, 1000 usuarios
            recommendations.append(f"ðŸ’° Costo estimado mensual (1K usuarios): ${monthly_cost_1k_users:.2f}")
            
            if monthly_cost_1k_users < 200:
                recommendations.append("âœ… Costos de OpenAI Vision son viables para MVP")
            else:
                recommendations.append("âš ï¸ Considerar optimizaciÃ³n de costos o modelo hÃ­brido")
        
        # RecomendaciÃ³n de stack
        recommendations.append("ðŸ—ï¸ Stack recomendado para MVP:")
        recommendations.append("   - VisiÃ³n: OpenAI Vision API (precisiÃ³n)")
        recommendations.append("   - NutriciÃ³n: USDA + Nutritionix (cobertura)")
        recommendations.append("   - Fallback: Modelo YOLO local (costos)")
        
        self.results["recommendations"] = recommendations
    
    def _save_comparison_results(self):
        """Guardar resultados de comparaciÃ³n"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"results/api_comparison_{timestamp}.json"
        
        Path("results").mkdir(exist_ok=True)
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        print(f"\nðŸ“„ ComparaciÃ³n guardada en: {filename}")
        self._print_comparison_summary()
    
    def _print_comparison_summary(self):
        """Imprimir resumen de la comparaciÃ³n"""
        print("\n" + "=" * 50)
        print("ðŸ“Š RESUMEN DE COMPARACIÃ“N")
        print("=" * 50)
        
        # Performance de OpenAI
        openai_perf = self.results["api_performance"].get("openai", {})
        if openai_perf:
            print(f"\nðŸ¤– OpenAI Vision Performance:")
            print(f"   â±ï¸  Tiempo promedio: {openai_perf.get('avg_processing_time', 0):.2f}s")
            print(f"   ðŸ’° Costo promedio: ${openai_perf.get('avg_cost_per_image', 0):.4f}/imagen")
            print(f"   âœ… Tasa de Ã©xito: {openai_perf.get('success_rate', 0)*100:.1f}%")
        
        # Recomendaciones
        print(f"\nðŸ’¡ RECOMENDACIONES:")
        for rec in self.results["recommendations"]:
            print(f"   {rec}")

def main():
    """Ejecutar comparaciÃ³n de APIs"""
    print("ðŸ”¬ COMPARADOR DE APIs - Contador de CalorÃ­as")
    print("Fase 1 - DÃ­as 3-4: EvaluaciÃ³n y ComparaciÃ³n")
    print("=" * 50)
    
    # Buscar imÃ¡genes de prueba
    test_images_dir = Path("test_images")
    if not test_images_dir.exists():
        print("âŒ Directorio test_images/ no encontrado")
        print("Ejecuta primero: python scripts/setup_environment.py")
        return
    
    # Buscar imÃ¡genes disponibles
    image_extensions = ['.jpg', '.jpeg', '.png']
    test_images = []
    
    for ext in image_extensions:
        test_images.extend(test_images_dir.glob(f"*{ext}"))
        test_images.extend(test_images_dir.glob(f"*{ext.upper()}"))
    
    if not test_images:
        print("âš ï¸  No se encontraron imÃ¡genes de prueba en test_images/")
        print("Agrega algunas imÃ¡genes de alimentos y ejecuta nuevamente")
        return
    
    print(f"ðŸ“¸ ImÃ¡genes encontradas: {len(test_images)}")
    for img in test_images:
        print(f"   - {img.name}")
    
    # Ejecutar comparaciÃ³n
    comparator = APIComparison()
    comparator.run_comparison([str(img) for img in test_images])

if __name__ == "__main__":
    main()